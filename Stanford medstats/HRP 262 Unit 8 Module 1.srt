1
00:00:05,600 --> 00:00:06,650
In this next module,

2
00:00:06,650 --> 00:00:10,330
I'm going to introduce you to generalized
estimating equations.

3
00:00:10,330 --> 00:00:13,290
For those of you who had HRP 261 in the
winter,

4
00:00:13,290 --> 00:00:15,640
you've actually already seen these models
before, but,

5
00:00:15,640 --> 00:00:18,916
what's new here is their application to
repeated-measures data.

6
00:00:21,910 --> 00:00:25,570
So generalized estimating equations are
used to analyze correlated data,

7
00:00:25,570 --> 00:00:28,401
including but not limited to,
repeated-measures.

8
00:00:29,530 --> 00:00:33,710
They're basically an extension of our
generalized linear models, but

9
00:00:33,710 --> 00:00:37,730
they estimate and explicitly account for
the correlations,

10
00:00:37,730 --> 00:00:40,710
whether those correlations are within
cluster or pairs of subjects or

11
00:00:40,710 --> 00:00:44,327
within the same subject over time, as in
repeated-measures.

12
00:00:47,280 --> 00:00:50,260
So take this data set that I've got
displayed up here, for example.

13
00:00:50,260 --> 00:00:51,780
Imagine that I give you this data set.

14
00:00:51,780 --> 00:00:53,050
It's in the long form.

15
00:00:53,050 --> 00:00:56,600
And this corresponds to, similar to the
data sets we've been talking about.

16
00:00:56,600 --> 00:00:59,440
I've got subjects who have had their bone
density measured at three

17
00:00:59,440 --> 00:01:04,650
time points about at baseline and about at
a year later and about two years later.

18
00:01:04,650 --> 00:01:07,680
If you didn't know anything about how to
account for correlation and

19
00:01:07,680 --> 00:01:11,000
I were to hand you this data set and say,
can you tell me whether or

20
00:01:11,000 --> 00:01:15,110
not the bone density changes significantly
over time, you might look at

21
00:01:15,110 --> 00:01:19,675
these data and say, well, okay, I have my
outcome variable is bone density.

22
00:01:19,675 --> 00:01:22,480
That's continuous and normally
distributed.

23
00:01:22,480 --> 00:01:25,070
Therefore, I'm going to be running a
linear regression model and

24
00:01:25,070 --> 00:01:26,850
my predictor will be time.

25
00:01:26,850 --> 00:01:29,120
And actually that's almost it.

26
00:01:29,120 --> 00:01:32,910
That's very close to what we are going to
be doing when we do a DE model,

27
00:01:32,910 --> 00:01:33,870
with one exception.

28
00:01:33,870 --> 00:01:35,220
We have to do something to account for

29
00:01:35,220 --> 00:01:37,970
the correlation, but it's going to look an
awful lot like this model.

30
00:01:37,970 --> 00:01:41,870
So I'm just going to start with just this
simple linear regression model run on

31
00:01:41,870 --> 00:01:42,970
the long form of the data.

32
00:01:44,140 --> 00:01:48,710
So if I run this linear regression model,
it corresponds to the picture on the left

33
00:01:48,710 --> 00:01:53,278
here, where I've graphed the spine bone
density of these women against time.

34
00:01:53,278 --> 00:01:56,690
This data set has 41 women in it.

35
00:01:56,690 --> 00:01:59,600
There's a lot of dots because women are
measured multiple times and

36
00:01:59,600 --> 00:02:03,510
notice that there's no way to connect
which dots go with themselves.

37
00:02:03,510 --> 00:02:07,940
You don't know which dots are connected by
being the same woman.

38
00:02:07,940 --> 00:02:11,520
However, you can fit a line to this
scatter plot, which I've done here.

39
00:02:11,520 --> 00:02:14,190
And you can see that there is a slight
positive slope here.

40
00:02:14,190 --> 00:02:18,500
So this spine bone density seems to be
going up a little bit over time.

41
00:02:18,500 --> 00:02:22,630
The equation of that line, we can get that
by fitting a linear regression model,

42
00:02:22,630 --> 00:02:24,240
which is what I've done.

43
00:02:24,240 --> 00:02:25,680
We can see the results over here.

44
00:02:26,740 --> 00:02:29,580
So the beta coefficient for time is indeed
positive.

45
00:02:29,580 --> 00:02:36,170
It comes out to be .005 spine bone density
on average is about a value of 1.0.

46
00:02:36,170 --> 00:02:41,290
So this corresponds to about a 0.5%
increase in spine bone density per year.

47
00:02:41,290 --> 00:02:42,580
Small, but important.

48
00:02:43,890 --> 00:02:47,160
And, however the P value is totally not
significant here.

49
00:02:48,470 --> 00:02:50,560
I want you to pay attention to the
standard error.

50
00:02:50,560 --> 00:02:54,248
The standard error is 0.01.

51
00:02:54,248 --> 00:03:00,320
So what's happening here is that our
standard error is too high.

52
00:03:00,320 --> 00:03:01,420
If you'll look at the picture here,

53
00:03:01,420 --> 00:03:05,360
you'll notice that there's a huge amount
of variability in spine bone density, but

54
00:03:05,360 --> 00:03:09,240
most of that variability doesn't have to
do with what's happening over time.

55
00:03:09,240 --> 00:03:12,220
It has to do with the fact that we have
different subjects and

56
00:03:12,220 --> 00:03:15,380
different people have vastly different
bone strength.

57
00:03:15,380 --> 00:03:17,730
You can see there's one person up here
this,

58
00:03:17,730 --> 00:03:20,710
you can imagine that probably this is the
same person over time.

59
00:03:20,710 --> 00:03:24,210
This person just genetically has really,
really high bone density.

60
00:03:24,210 --> 00:03:26,830
There's other people who tend to be very
low.

61
00:03:26,830 --> 00:03:31,580
The bulk of the variability in bone
density has to do which subject you are.

62
00:03:31,580 --> 00:03:37,010
And, this is going to be analogous to last
week in repeated-measures,

63
00:03:37,010 --> 00:03:40,940
univariate anova, we calculated the
between subject variation.

64
00:03:40,940 --> 00:03:44,810
Once we've accounted for that between
subject variation, our standard errors,

65
00:03:44,810 --> 00:03:48,550
our unexplained variability shrank a huge
deal.

66
00:03:48,550 --> 00:03:50,890
Well, we're going to basically do the same
thing here.

67
00:03:50,890 --> 00:03:54,470
If we can account for which, which of the
part of the variability is just due to

68
00:03:54,470 --> 00:03:58,174
the fact that we have different subjects,
we can greatly shrink our standard errors,

69
00:03:58,174 --> 00:04:00,840
that means our P values are also going to
get smaller.

70
00:04:00,840 --> 00:04:02,640
So that's all that GE does.

71
00:04:02,640 --> 00:04:05,940
It connects which of these dots goes with
which of

72
00:04:05,940 --> 00:04:08,310
the other dots which is the same person
over time.

73
00:04:09,660 --> 00:04:12,880
And the model doesn't look that different
from a regular linear regression.

74
00:04:12,880 --> 00:04:18,270
The only difference is that we have this
correction factor for correlation.

75
00:04:18,270 --> 00:04:20,780
So essentially, this is a nuisance
variable.

76
00:04:20,780 --> 00:04:23,430
We're going to be estimating a correlation
matrix.

77
00:04:23,430 --> 00:04:24,920
If you don't explicitly ask for it,

78
00:04:24,920 --> 00:04:28,100
you won't even see it in your SAS output,
for example.

79
00:04:28,100 --> 00:04:31,240
But we need to estimate that in order to
be able to correct for

80
00:04:31,240 --> 00:04:32,890
the between subject variability.

81
00:04:34,350 --> 00:04:38,110
So I went ahead and ran the correct model
now, just to show you the difference.

82
00:04:39,470 --> 00:04:40,770
So the picture is still the same.

83
00:04:40,770 --> 00:04:43,390
We've still got spine bone density over
time.

84
00:04:43,390 --> 00:04:46,650
It's the overall increase is a slight
positive increase.

85
00:04:46,650 --> 00:04:50,740
But when I correct for this correlation
within subject,

86
00:04:50,740 --> 00:04:53,690
what you'll notice is that the beta
coefficient for time doesn't change much.

87
00:04:53,690 --> 00:04:54,810
It's still positive.

88
00:04:54,810 --> 00:04:59,180
It's now a little bit higher, about a 0.8,
0.9% increase per year.

89
00:04:59,180 --> 00:05:02,920
But, what really changes here the, the
effect of accounting for

90
00:05:02,920 --> 00:05:07,690
a correlation, what affect that has is to
hugely effect the standard errors.

91
00:05:07,690 --> 00:05:12,140
So, remember our standard errors before
were 0.01.

92
00:05:12,140 --> 00:05:15,860
Our standard error goes from 0.01 down to
0.002, so

93
00:05:15,860 --> 00:05:19,565
it's, we've actually cut our standard
error by five fold.

94
00:05:19,565 --> 00:05:24,530
So the bulk of the variation here was just
due to the different subjects.

95
00:05:24,530 --> 00:05:28,000
And once we've accounted for that our
standard errors are much, much smaller and

96
00:05:28,000 --> 00:05:31,180
notice now that our P value is highly
significant.

97
00:05:31,180 --> 00:05:33,950
So this is a true increase over time.

98
00:05:33,950 --> 00:05:35,320
It's a small increase, but

99
00:05:35,320 --> 00:05:39,500
it is a statistically significant increase
in bone density over time within women.

100
00:05:40,570 --> 00:05:43,320
Notice that when we're asking about
changes over time we're

101
00:05:43,320 --> 00:05:45,880
talking about within subjects comparisons.

102
00:05:45,880 --> 00:05:47,850
When we fail to account for correlations
for

103
00:05:47,850 --> 00:05:51,720
within subjects comparisons, as I've told
you before, then our P values and

104
00:05:51,720 --> 00:05:54,110
our standard errors are too high as you
see here.

105
00:05:54,110 --> 00:05:55,110
When we correctly account for

106
00:05:55,110 --> 00:05:58,760
those correlations then those p values and
standard errors come down.

107
00:05:58,760 --> 00:06:02,270
So that's the idea of generalizing
estimating equations.

108
00:06:02,270 --> 00:06:04,479
We're essentially going to be changing
those standard errors

109
00:06:06,070 --> 00:06:09,250
adjusting the standard error based on the
correlation within subject.

110
00:06:10,270 --> 00:06:13,600
Let me go now into a little bit more about
the mechanics of

111
00:06:13,600 --> 00:06:15,020
generalized estimating equations.

112
00:06:16,880 --> 00:06:19,310
So, what's actually happening behind the
scenes in the computer?

113
00:06:20,520 --> 00:06:21,460
So, as I've mentioned,

114
00:06:21,460 --> 00:06:24,550
it's not really that different than
fitting a regular linear regression.

115
00:06:24,550 --> 00:06:26,160
What the computer is actually doing is it,

116
00:06:26,160 --> 00:06:29,740
in fact, first fits a regular old linear
regression,

117
00:06:29,740 --> 00:06:32,450
assuming that the observations within
subjects are completely independent.

118
00:06:34,350 --> 00:06:37,570
It then calculates the residuals from that
linear regression.

119
00:06:37,570 --> 00:06:39,980
So the observed minus predicted values for
everybody.

120
00:06:41,050 --> 00:06:45,580
Those residuals are going to reflect the
pattern of correlations in the data.

121
00:06:45,580 --> 00:06:46,910
It takes those residuals and

122
00:06:46,910 --> 00:06:50,780
uses them to estimate what's called a
working correlation matrix.

123
00:06:50,780 --> 00:06:56,140
And the one constraint is that you do have
to a priory specify a structure for

124
00:06:56,140 --> 00:06:57,250
that correlation matrix.

125
00:06:57,250 --> 00:07:00,680
I'm going to show you the different
choices in a few minutes here.

126
00:07:00,680 --> 00:07:04,950
It's going to then refit that linear
regression model but

127
00:07:04,950 --> 00:07:07,880
now correcting for the correlation.

128
00:07:07,880 --> 00:07:11,540
And it's going to calculate the residuals
from that new model and

129
00:07:11,540 --> 00:07:15,380
then estimate a new working correlation
matrix and it's iterative process.

130
00:07:15,380 --> 00:07:19,145
So it's going to keep going through this
over and again until it can,

131
00:07:19,145 --> 00:07:20,390
until the model converges.

132
00:07:23,300 --> 00:07:26,710
And essentially we're estimating this
working correlation matrix,

133
00:07:26,710 --> 00:07:29,460
this within correlate subject correlation
structure.

134
00:07:29,460 --> 00:07:30,430
We're estimating it so

135
00:07:30,430 --> 00:07:33,730
that we can get the correct standard
errors but it's a nuisance variable.

136
00:07:33,730 --> 00:07:37,970
If you don't explicitly ask for it in the
outputting staff, you won't even see it.

137
00:07:37,970 --> 00:07:39,070
It's not what we care about,

138
00:07:39,070 --> 00:07:41,620
it's just that we care about getting the
standard errors correct.

139
00:07:41,620 --> 00:07:45,800
I just want to point out quickly here that
we've

140
00:07:45,800 --> 00:07:51,350
talked a lot about maximum likelihood
estimation and about likelihood functions.

141
00:07:51,350 --> 00:07:54,180
You've all thought about likelihood
functions in

142
00:07:54,180 --> 00:07:56,420
the concept of survival analysis.

143
00:07:56,420 --> 00:08:00,260
I want to point out that, in fact, when
you have correlated data it's

144
00:08:00,260 --> 00:08:05,500
very difficult to correctly specify the
entire likelihood function,

145
00:08:05,500 --> 00:08:10,030
because it's complicated by the fact that
we don't have independent observations.

146
00:08:10,030 --> 00:08:13,730
So we don't actually do maximum likelihood
estimation methods.

147
00:08:13,730 --> 00:08:16,520
We do what are called quasi-likelihood
methods for

148
00:08:16,520 --> 00:08:18,560
generalized estimating equations.

149
00:08:18,560 --> 00:08:20,530
I'm not going to go in to any of the
details on that, but

150
00:08:20,530 --> 00:08:25,160
basically it saves you having to specify
the likelihood function exactly,

151
00:08:25,160 --> 00:08:28,970
which is beneficial when you have this
complication of correlation.

152
00:08:28,970 --> 00:08:32,630
But it has a lot of the advantages of
maximum likelihood estimation.

153
00:08:32,630 --> 00:08:35,480
And, as a result of the fact that we're
doing quasi-likelihood rather than

154
00:08:35,480 --> 00:08:39,360
maximum likelihood methods, what you'll
notice in your output,

155
00:08:39,360 --> 00:08:42,430
is that you're going to get a QIC instead
of an AIC.

156
00:08:42,430 --> 00:08:47,720
So remember that we use the AIC previously
to as a measurable of model fit and

157
00:08:47,720 --> 00:08:50,610
that comes directly from the likelihood
function.

158
00:08:50,610 --> 00:08:54,070
Since we do have a likely hood function
here, we have a quasi-likelihood function,

159
00:08:54,070 --> 00:08:57,552
we're instead going to get a QIC, Q coming
from the word quasi.

160
00:08:57,552 --> 00:09:01,340
It's essentially analogous to the AIC but

161
00:09:01,340 --> 00:09:04,790
it's based on the quasi-likelihood rather
than the maximum likelihood function.

162
00:09:04,790 --> 00:09:07,660
So, we're going to treat it as we would
the AIC.

163
00:09:07,660 --> 00:09:10,470
The smaller values indicate a better model
fit.

164
00:09:10,470 --> 00:09:12,370
The QIC is very useful for

165
00:09:12,370 --> 00:09:15,500
helping you to select the best working
correlation structure.

166
00:09:17,740 --> 00:09:20,820
So again, when you're asking the computer
to run your

167
00:09:20,820 --> 00:09:24,160
generalized estimating equations you do
have to specify up front what type of

168
00:09:24,160 --> 00:09:25,360
correlation structure you want.

169
00:09:27,480 --> 00:09:32,110
GEE luckily is fairly robust against the
wrong choice of correlation matrix.

170
00:09:32,110 --> 00:09:33,740
Particularly if you've got a large sample
size.

171
00:09:33,740 --> 00:09:35,120
So if you get it wrong,

172
00:09:35,120 --> 00:09:37,620
you're going to see that it's not going to
necessarily make a huge difference.

173
00:09:37,620 --> 00:09:40,410
But obviously we'd like to spend some time
thinking about what is

174
00:09:40,410 --> 00:09:42,130
the best correlation structure for our
data.

175
00:09:42,130 --> 00:09:45,640
I'm going to give you some different
examples of correlation structures that

176
00:09:45,640 --> 00:09:48,650
you have as choices at your disposal.

177
00:09:48,650 --> 00:09:51,870
So, I'll go through each one of these in
turn to say exactly what

178
00:09:51,870 --> 00:09:53,570
that structure looks like.

179
00:09:53,570 --> 00:09:56,920
But basically we're looking for simplest
structure, the one that uses up the fewest

180
00:09:56,920 --> 00:10:00,030
degrees of freedom, the simplest structure
that fits the data well.

181
00:10:00,030 --> 00:10:03,390
And again, you can use this QIC to help
you decide which one is the best one.

182
00:10:04,410 --> 00:10:06,890
So let me just show you what all these
correlation structures look like.

183
00:10:06,890 --> 00:10:11,220
So first of all, the, an independent
correlation structure is when you're

184
00:10:11,220 --> 00:10:15,320
assuming that all of the time points are
independent of one another.

185
00:10:15,320 --> 00:10:19,110
This is clearly probably not going to be
the correct correlation structure if you

186
00:10:19,110 --> 00:10:20,730
have repeated measures data.

187
00:10:20,730 --> 00:10:22,700
If you have correlations, you don't have
independence.

188
00:10:22,700 --> 00:10:25,170
But I'm just showing you this is the one
that we're,

189
00:10:25,170 --> 00:10:29,010
we're assuming independence when we fit a
regular linear regression and

190
00:10:29,010 --> 00:10:31,910
this what I'm showing you here is a
correlation matrix.

191
00:10:31,910 --> 00:10:35,460
Imagine we've got a data set that has four
time points and I ask for

192
00:10:35,460 --> 00:10:37,700
the correlation between any two time
points.

193
00:10:37,700 --> 00:10:40,370
If they're zero, if a person isn't
correlated to themselves at

194
00:10:40,370 --> 00:10:44,490
different time points again, unrealistic,
that would, be then you would be on,

195
00:10:44,490 --> 00:10:46,310
on an independent correlation structure.

196
00:10:47,330 --> 00:10:48,440
That's usually not the right choice.

197
00:10:50,110 --> 00:10:53,990
The simplest correlation structure that
actually has correlation between different

198
00:10:53,990 --> 00:10:56,180
time points is what was called the
exchangeable,

199
00:10:56,180 --> 00:10:58,360
this is we talked about compound symmetry
last week so.

200
00:10:58,360 --> 00:11:00,410
So this is the same as compound symmetry.

201
00:11:00,410 --> 00:11:05,510
This is saying that any, the correlation
between any two time points is equal.

202
00:11:05,510 --> 00:11:07,920
So for example, the correlation between
time one and

203
00:11:07,920 --> 00:11:11,730
time two is the same as the correlation
between time one and time three, and

204
00:11:11,730 --> 00:11:15,250
is the same as the correlation between
time one and time four.

205
00:11:15,250 --> 00:11:19,570
Now you can imagine that the advantage of
the exchangeable correlation matrix is

206
00:11:19,570 --> 00:11:23,780
that you actually are modelling and
accounting for correlation.

207
00:11:23,780 --> 00:11:27,305
However you only had to estimate one
parameter.

208
00:11:27,305 --> 00:11:29,080
There's one correlation parameter to
estimate so

209
00:11:29,080 --> 00:11:32,380
it doesn't cost you a lot of degrees of
freedom, so that's an advantage.

210
00:11:32,380 --> 00:11:34,917
The disadvantage is that, especially for

211
00:11:34,917 --> 00:11:39,120
repeated-measures outcomes, you can
imagine as you get further and

212
00:11:39,120 --> 00:11:43,040
further apart in time, probably the
correlations are going to go down.

213
00:11:43,040 --> 00:11:47,540
People as you drift in time, you're likely
to drift in your values and

214
00:11:47,540 --> 00:11:50,660
therefore, you would expect that if you're
three time points away rather

215
00:11:50,660 --> 00:11:53,600
than one time point away that you might
have a smaller correlation.

216
00:11:53,600 --> 00:11:56,680
So the exchangeable isn't always the right
choice for repeated measures for

217
00:11:56,680 --> 00:11:57,190
that reason.

218
00:11:58,280 --> 00:12:01,950
Another choice you have is the
unstructured correlation matrix.

219
00:12:01,950 --> 00:12:05,702
The issue with the unstructured is that it
uses up a lot of degrees of freedom.

220
00:12:05,702 --> 00:12:07,130
So unstructured just says for

221
00:12:07,130 --> 00:12:10,460
every possible correlation coefficient,
estimate a new one.

222
00:12:10,460 --> 00:12:13,850
So, if there are six pairs of time points,
estimate for

223
00:12:13,850 --> 00:12:15,548
me six correlation coefficients.

224
00:12:15,548 --> 00:12:18,410
Obviously, that's going to be very
precise, but

225
00:12:18,410 --> 00:12:20,100
it eats up a lot of degrees of freedom.

226
00:12:21,420 --> 00:12:25,100
If you have four time points, you're going
to have four choose two, which is

227
00:12:25,100 --> 00:12:28,600
six correlations to estimate, If you have
five you will have five choose two,

228
00:12:28,600 --> 00:12:31,350
which is ten correlations to estimate, and
so on.

229
00:12:31,350 --> 00:12:34,880
So you can see that this can get untenable
rather quickly.

230
00:12:34,880 --> 00:12:37,910
However, if you've got a situation where
you've got a large number of subjects and

231
00:12:37,910 --> 00:12:42,180
a, only a small number of time periods you
have sort of unlimited degrees of

232
00:12:42,180 --> 00:12:44,840
freedom and, you know, you're not going to
eat up too many of those degrees of

233
00:12:44,840 --> 00:12:47,680
freedom if you only have, say, three time
periods.

234
00:12:47,680 --> 00:12:50,860
Then, the unstructured might be a good
choice in that situation.

235
00:12:53,570 --> 00:12:59,170
The autoregressive is kind of a compromise
between exchangeable and unstructured.

236
00:12:59,170 --> 00:13:03,030
So, there's only one parameter to
estimate, as in the exchangeable, but

237
00:13:03,030 --> 00:13:06,320
it's allowing some flexibility, so that
you actually have different

238
00:13:06,320 --> 00:13:09,530
correlations across different time
periods.

239
00:13:09,530 --> 00:13:13,240
So the way the autoregressive works is,
this works well for repeated measures

240
00:13:13,240 --> 00:13:20,090
data, is that it starts with estimating a
correlation between adjacent time periods.

241
00:13:20,090 --> 00:13:22,210
So it's saying that there's a,

242
00:13:22,210 --> 00:13:26,450
one correlation that describes all of the
adjacent time periods.

243
00:13:26,450 --> 00:13:28,490
And then if we're two time periods away,

244
00:13:28,490 --> 00:13:30,500
the correlations is going to be a little
bit smaller.

245
00:13:30,500 --> 00:13:31,840
And if we're three time periods away,

246
00:13:31,840 --> 00:13:33,780
the correlation is going to be even a
little bit smaller.

247
00:13:33,780 --> 00:13:36,990
This often describe repeated-measures
data.

248
00:13:36,990 --> 00:13:40,330
And the way we can get away with only
estimating a single parameter here is

249
00:13:40,330 --> 00:13:42,620
a little tricky, if you've noticed what
they done,

250
00:13:42,620 --> 00:13:47,470
is you take the correlation from one time
period away and you square it.

251
00:13:47,470 --> 00:13:50,920
Well, if you square a number that less
than one it's going to

252
00:13:50,920 --> 00:13:52,390
be a little bit smaller.

253
00:13:52,390 --> 00:13:55,020
And then you can cube it for three time
periods away and so on.

254
00:13:55,020 --> 00:13:59,130
So this way you get diminishing
correlation as you go further and

255
00:13:59,130 --> 00:14:02,500
further apart in time, but it only costs
you one degree of freedom.

256
00:14:02,500 --> 00:14:04,690
So very useful in repeated-measures data,
often.

257
00:14:05,870 --> 00:14:10,080
The independent correlation structure is
trying to do the same sort of thing,

258
00:14:10,080 --> 00:14:11,700
which is to recognize that often for

259
00:14:11,700 --> 00:14:15,830
repeated method data, if you're one time
point away, you have a different

260
00:14:15,830 --> 00:14:20,230
correlation than say if you're two times
points away, or three time periods away.

261
00:14:20,230 --> 00:14:23,960
So what it does is it allows you to
estimate one correlation width for

262
00:14:23,960 --> 00:14:27,050
one time period away but then it doesn't
assume that you

263
00:14:27,050 --> 00:14:29,560
can just square that one to get to two
time periods away.

264
00:14:29,560 --> 00:14:33,060
It estimates a whole separate correlation
for two time periods away.

265
00:14:33,060 --> 00:14:36,460
And then you can do, if you did three
dependent here we could

266
00:14:36,460 --> 00:14:40,210
estimate a whole separate correlation for
three time periods away or at some point,

267
00:14:40,210 --> 00:14:43,010
you might say that we're far enough away
that they're no longer correlated,

268
00:14:43,010 --> 00:14:44,670
you just set them equal to zero.

269
00:14:44,670 --> 00:14:47,760
So we could do two-dependent or
three-dependent here.

270
00:14:47,760 --> 00:14:49,235
Another one that is often useful for

271
00:14:49,235 --> 00:14:52,100
repeated-measures data costs you a few
more degrees of freedom, but

272
00:14:52,100 --> 00:14:54,990
certainly not as many degrees of freedom
in an unstructured matrix.

273
00:14:57,320 --> 00:14:59,240
So how do you chose the working
correlation structure?

274
00:14:59,240 --> 00:15:03,400
Again, generalized estimating equations
are fairly robust against the choice of

275
00:15:03,400 --> 00:15:06,640
correlation structure, so you don't have
to stress about it too much.

276
00:15:06,640 --> 00:15:09,780
But often the nature of the problem
suggests the choice of structure.

277
00:15:09,780 --> 00:15:13,005
So, for example, for repeated-measures
data, autoregressive or

278
00:15:13,005 --> 00:15:16,180
m-dependent are often appropriate for the
reasons I've talked about.

279
00:15:16,180 --> 00:15:19,490
Exchangeable will also if the changes over
time aren't too big.

280
00:15:20,710 --> 00:15:23,410
If you have clusters in your data that
don't have any natural orderling,

281
00:15:23,410 --> 00:15:27,210
ordering like time then the exchangeable
would be recommended.

282
00:15:27,210 --> 00:15:30,760
If you have a situation where you have a
huge number of clusters and not so

283
00:15:30,760 --> 00:15:32,070
many measurements within clusters,

284
00:15:32,070 --> 00:15:34,710
sometimes even the independent structure
may suffice.

285
00:15:34,710 --> 00:15:38,560
But you can use again the QIC to help
guide this, the choice.

286
00:15:38,560 --> 00:15:39,930
And I'll give you an example in a minute.

287
00:15:39,930 --> 00:15:41,150
You're looking for the lowest QIC.

288
00:15:43,780 --> 00:15:47,110
So take this example data on bone density
that we've been using.

289
00:15:47,110 --> 00:15:50,220
I went ahead and just asked for the
empirical correlation matrix.

290
00:15:50,220 --> 00:15:54,213
So what are the correlations between each
time period?

291
00:15:54,213 --> 00:15:57,570
So I took, I'm getting, showing you here
there's only three time periods for

292
00:15:57,570 --> 00:15:58,240
this data set.

293
00:15:58,240 --> 00:16:01,560
So I'm getting the correlation between the
second spine measurement and

294
00:16:01,560 --> 00:16:02,600
the first spine measurement.

295
00:16:02,600 --> 00:16:05,090
That was actually the highest at .979.

296
00:16:05,090 --> 00:16:06,890
The correlation between the second and

297
00:16:06,890 --> 00:16:12,130
the third, which are only one time point
adjacent, was 0.974, so pretty close.

298
00:16:12,130 --> 00:16:13,940
And then the correlation between the first
and

299
00:16:13,940 --> 00:16:17,440
the last was just a teeny bit smaller at
0.966.

300
00:16:17,440 --> 00:16:20,290
You can see that they're all very similar,

301
00:16:20,290 --> 00:16:23,460
because the bone density wasn't changing a
huge amount over time.

302
00:16:23,460 --> 00:16:25,500
It takes your skeleton quite a bit of time
to change,

303
00:16:25,500 --> 00:16:26,800
especially when you're already an adult.

304
00:16:28,740 --> 00:16:31,210
So which correlation matrix would this
correspond to?

305
00:16:31,210 --> 00:16:34,966
Well, we could choose the exchangeable,
because they're all right around 0.96,

306
00:16:34,966 --> 00:16:36,040
0.97, 0.98.

307
00:16:36,040 --> 00:16:39,030
Probably exchangeable would be just fine.

308
00:16:39,030 --> 00:16:42,890
The when I showed you the run of GEE
before.

309
00:16:42,890 --> 00:16:46,110
I actually for these data, I just chose
the exchangeable.

310
00:16:46,110 --> 00:16:49,140
You could also argue that maybe
autoregressive would be appropriate,

311
00:16:49,140 --> 00:16:53,820
because you can see that the correlation
between the first two and

312
00:16:53,820 --> 00:16:55,060
the second two time periods,

313
00:16:55,060 --> 00:16:58,620
those are a little bit higher than the
correlation from the first to the last.

314
00:16:58,620 --> 00:17:01,290
So, maybe autoregressive would work here
as well.

315
00:17:01,290 --> 00:17:04,340
You could also choose unstructured because
we only have

316
00:17:04,340 --> 00:17:05,640
three correlations to estimate.

317
00:17:05,640 --> 00:17:07,990
Although this data set only has 41 women
in it, so

318
00:17:07,990 --> 00:17:10,390
we're limited on degrees of freedom.

319
00:17:10,390 --> 00:17:11,060
I went ahead and

320
00:17:11,060 --> 00:17:13,960
fit all of these different correlation
structures just to compare them.

321
00:17:13,960 --> 00:17:15,070
See what happens.

322
00:17:15,070 --> 00:17:17,480
So I started with the exchangeable
correlation matrix.

323
00:17:17,480 --> 00:17:19,610
I've already showed you these results
before.

324
00:17:19,610 --> 00:17:22,200
So the beta coefficient was 0.0088.

325
00:17:22,200 --> 00:17:24,110
My P value is highly significant.

326
00:17:24,110 --> 00:17:26,656
My standard error is about 0.002.

327
00:17:26,656 --> 00:17:29,445
The exchangeable working correlation is
0.974.

328
00:17:29,445 --> 00:17:33,040
There it estimated for all of the
correlations about 0.974.

329
00:17:33,040 --> 00:17:37,111
That seems like a good compromise, because
they were all right around 0.96,

330
00:17:37,111 --> 00:17:38,326
0.97, 0.98.

331
00:17:38,326 --> 00:17:41,521
I then want to have them fit the
autoregressive, oh so

332
00:17:41,521 --> 00:17:45,100
the the, the QIC from the exchangeable is
126.88.

333
00:17:45,100 --> 00:17:46,880
I went ahead and fit the autoregressive.

334
00:17:46,880 --> 00:17:50,950
You'll notice that the QIC was just teeny,
teeny bit better from the auto regressive.

335
00:17:50,950 --> 00:17:53,570
Although I would consider these models to
be equally good.

336
00:17:53,570 --> 00:17:55,320
They're, that QIC isn't very different.

337
00:17:55,320 --> 00:17:57,350
But it is a little bit better from the
autoregressive.

338
00:17:57,350 --> 00:17:59,520
So maybe the autoregressive is just
slightly better here.

339
00:18:01,002 --> 00:18:06,042
For the autoregressive you can see that it
says 0.9975 for one time-point adjacent

340
00:18:06,042 --> 00:18:11,130
and 0.9949 for two time-points adjacent,
which is just the square of 0.9975.

341
00:18:11,130 --> 00:18:14,980
It doesn't affect the model much at all.

342
00:18:14,980 --> 00:18:17,020
The beta coefficient is0 .0098, so

343
00:18:17,020 --> 00:18:20,510
just slightly higher than with the
exchangeable, basically the same.

344
00:18:20,510 --> 00:18:25,240
The standard error is pretty close 0.0024,
rather than .0021, so pretty similar.

345
00:18:25,240 --> 00:18:28,170
The P value is still highly significant.

346
00:18:28,170 --> 00:18:30,130
So it doesn't change things a whole heck
of a lot.

347
00:18:30,130 --> 00:18:31,540
Either of those would be a good choice
here.

348
00:18:33,890 --> 00:18:36,030
I then went ahead and fit the
unstructured.

349
00:18:36,030 --> 00:18:38,260
Now again, there's only three time periods
here.

350
00:18:38,260 --> 00:18:40,590
So, you know, when you only have three
time periods and

351
00:18:40,590 --> 00:18:42,870
unstructured might normally do pretty well
but

352
00:18:42,870 --> 00:18:46,000
because there's only 41 people in my data
set it really blew up the QIC.

353
00:18:46,000 --> 00:18:50,480
There's something funny going on when the
QIC gets that big.

354
00:18:50,480 --> 00:18:54,137
If you can see that it's at 0.9956, 0
.9876, and

355
00:18:54,137 --> 00:18:57,510
0.9690, all different correlations.

356
00:18:57,510 --> 00:19:00,860
It didn't really impact the outcomes so
much.

357
00:19:00,860 --> 00:19:02,780
The beta estimate's a little bit higher
now and

358
00:19:02,780 --> 00:19:04,990
the standard error is actually almost
double.

359
00:19:04,990 --> 00:19:06,590
So that made our P value a little bit
higher, but

360
00:19:06,590 --> 00:19:08,390
it still came out to be statistically
significant.

361
00:19:08,390 --> 00:19:10,570
This probably would not be the best choice
here.

362
00:19:10,570 --> 00:19:14,620
Although again, if we had a bigger data
set, the unstructured might do fine.

363
00:19:14,620 --> 00:19:17,870
I also went ahead and fit the independent
correlation matrix.

364
00:19:17,870 --> 00:19:20,970
This is where all of the correlations get
set to zero.

365
00:19:20,970 --> 00:19:22,620
So the correlation matrix would look like
this.

366
00:19:22,620 --> 00:19:26,490
Now, of course, that's totally the wrong
correlation.

367
00:19:26,490 --> 00:19:28,030
We certainly have correlation here.

368
00:19:28,030 --> 00:19:31,950
But what I want to point out to you is
that the QIC is higher than for

369
00:19:31,950 --> 00:19:34,120
the exchangeable or the autoregressive, as
it should be,

370
00:19:34,120 --> 00:19:36,480
because it's certainly not as good as a
choice.

371
00:19:36,480 --> 00:19:40,240
However, it didn't make, it does make some
impact here,

372
00:19:40,240 --> 00:19:45,510
but we still do a lot better then when we
just ran a regular old linear regression.

373
00:19:45,510 --> 00:19:49,460
So the point estimate turns out to be
0.005.

374
00:19:49,460 --> 00:19:52,210
The standard error is pretty big.

375
00:19:52,210 --> 00:19:55,870
The P value is no longer significant, but
this is still better.

376
00:19:55,870 --> 00:19:59,750
Remember, the standard error when we get a
regular linear regression was 0.01,

377
00:19:59,750 --> 00:20:02,880
so we've still done a lot better than
that.

378
00:20:02,880 --> 00:20:06,320
And the reason that the independent, if
you choose independent,

379
00:20:06,320 --> 00:20:10,540
you still don't do too badly especially if
you've got a bigger sample size,

380
00:20:10,540 --> 00:20:14,440
is that you're using what I'm showing you
here are the empirical or

381
00:20:14,440 --> 00:20:17,700
robust standard errors, which I've talked
about before.

382
00:20:17,700 --> 00:20:21,920
If you ask for the robust standard errors
or the empirical standard errors, then

383
00:20:21,920 --> 00:20:25,500
the estimates are fairly robust against
the choice of correlation structure.

384
00:20:25,500 --> 00:20:28,770
So we even don't do too badly if we choose
the independent correlation structure,

385
00:20:28,770 --> 00:20:31,240
which is obviously wrong.

386
00:20:31,240 --> 00:20:32,410
So again, there's two types of

387
00:20:32,410 --> 00:20:35,920
standard errors that you can get out of
the generalized estimating equations.

388
00:20:35,920 --> 00:20:39,030
You're mostly always going to want to
choose the robust standard errors.

389
00:20:39,030 --> 00:20:40,680
There may be a few exceptions to that,
but,

390
00:20:40,680 --> 00:20:43,230
in general, the robust standard errors are
preferred,

391
00:20:43,230 --> 00:20:47,140
because they are robust against the
incorrect choice of correlation structure.

392
00:20:47,140 --> 00:20:50,460
It's not going to make a huge difference
which correlation structure you choose for

393
00:20:50,460 --> 00:20:53,490
the most part, especially if the sample
size is large.

394
00:20:53,490 --> 00:20:56,360
If you're doing this in SAS, it just gives
you the robust or

395
00:20:56,360 --> 00:20:58,180
empirical errors without you asking.

396
00:21:00,140 --> 00:21:02,836
However, there are another type of
standard errors called the model-based

397
00:21:02,836 --> 00:21:06,200
standard errors.These are very sensitive
to the choice of correlation structure.

398
00:21:06,200 --> 00:21:08,980
And there may be a few instances when you
want to use these,

399
00:21:08,980 --> 00:21:13,220
specifically if you have a very low number
of clusters then the model based

400
00:21:13,220 --> 00:21:15,110
standard errors may be preferred.

401
00:21:15,110 --> 00:21:19,445
This is not generally be the case when you
have repeated-measures data, because for

402
00:21:19,445 --> 00:21:22,830
repeated-measures data the cluster is the
subject and you know it's

403
00:21:22,830 --> 00:21:27,456
very aware that you'd have a data set with
less than 20 subjects measured over time.

404
00:21:27,456 --> 00:21:31,660
That certainly could happen but for the
most case, for repeated-measures data,

405
00:21:31,660 --> 00:21:34,530
usually we're going to have a large enough
number of clusters.

406
00:21:34,530 --> 00:21:38,010
So but you may get a situation where
you've got cluster data where people are,

407
00:21:38,010 --> 00:21:41,140
say, clustered by school or something and
you only have ten schools in the data set.

408
00:21:41,140 --> 00:21:43,410
Then you would want to consider the
model-based standard errors.

409
00:21:43,410 --> 00:21:46,490
But, in general, we're going to be using
those robust standard errors,

410
00:21:46,490 --> 00:21:47,960
which helps us,

411
00:21:47,960 --> 00:21:52,610
because it guards us against any problems
in our choice of correlation structure.

412
00:21:52,610 --> 00:21:54,820
And I just want to show you the
model-based standard errors,

413
00:21:54,820 --> 00:21:58,860
when I choose the independence correlation
structure and

414
00:21:58,860 --> 00:22:02,600
I then choose the model-based standard
errors, I really get things wrong.

415
00:22:02,600 --> 00:22:06,503
I actually back to the just the original
linear regression that I showed you at

416
00:22:06,503 --> 00:22:09,980
the beginning of this module where I did
nothing to account for the correlations.

417
00:22:09,980 --> 00:22:13,900
I get back at standard error of 0.01 and
the non-significant P value.

418
00:22:13,900 --> 00:22:18,910
So clearly, we don't want to use
independence correlation structure.

419
00:22:18,910 --> 00:22:21,730
And again, this is just to show you that
the model-based standard errors are really

420
00:22:21,730 --> 00:22:24,310
sensitive to that choice of correlation
structure.

421
00:22:24,310 --> 00:22:29,499
[BLANK_AUDIO]
