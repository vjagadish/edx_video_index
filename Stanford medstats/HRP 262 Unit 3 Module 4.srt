1
00:00:00,000 --> 00:00:05,400
[BLANK_AUDIO]

2
00:00:05,400 --> 00:00:08,890
In this next module, I'm going to tell you
about the different residuals that

3
00:00:08,890 --> 00:00:10,810
are available for Cox regression.

4
00:00:12,000 --> 00:00:16,950
So remember, residuals are useful for
testing assumptions about the model,

5
00:00:16,950 --> 00:00:21,000
we use them a lot, in linear regression,
for example, to say whether or

6
00:00:21,000 --> 00:00:24,840
not we had any violations of the
assumptions of linear regression.

7
00:00:24,840 --> 00:00:31,340
A residual is just some kind of observed
minus predicted for each individual.

8
00:00:31,340 --> 00:00:33,330
So you have a predicted value from the
model.

9
00:00:33,330 --> 00:00:35,030
You've got an observed value from each
person.

10
00:00:35,030 --> 00:00:38,239
You subtract those in some fashion that
gives you a residual.

11
00:00:39,330 --> 00:00:40,420
Now for Cox regression,

12
00:00:40,420 --> 00:00:45,010
it's a little tricky because the outcome
variable is a two part variable, right?

13
00:00:45,010 --> 00:00:48,130
We have time and we have whether or not
they had the event.

14
00:00:48,130 --> 00:00:51,920
So what's the predicted value of Cox
regression going to be?

15
00:00:51,920 --> 00:00:54,060
It's not quite straightforward.

16
00:00:55,290 --> 00:00:59,040
So there's a couple of different types of
residuals that people have come up with.

17
00:00:59,040 --> 00:01:01,540
So first of all, there's something called
a Martingale residual, and

18
00:01:01,540 --> 00:01:03,370
the basic idea with the Martingale
residual is,

19
00:01:03,370 --> 00:01:05,840
we're going to look at whether or not you
had the event.

20
00:01:05,840 --> 00:01:09,070
We're going to compare that to your
probability of having the event

21
00:01:09,070 --> 00:01:10,160
at a given time.

22
00:01:10,160 --> 00:01:15,480
So every person either has the event, or
they're censored at their event time, Ti.

23
00:01:15,480 --> 00:01:18,910
And what we can do is we can say, okay,
you got a one or a zero depending on

24
00:01:18,910 --> 00:01:21,970
whether you've had the event, or you're
censored, and then based on the model,

25
00:01:21,970 --> 00:01:25,990
we can come out with a cumulative or
predictive cumulative hazard.

26
00:01:25,990 --> 00:01:30,270
That's the predicted probability that you
would have had the event by time t.

27
00:01:30,270 --> 00:01:34,290
And t is how long a person was in the
study until they were censored or

28
00:01:34,290 --> 00:01:35,500
had the event.

29
00:01:35,500 --> 00:01:36,370
Let me just give an example.

30
00:01:36,370 --> 00:01:39,060
So, for a subject that was censored at two
months, and

31
00:01:39,060 --> 00:01:41,750
whose predicted cumulative hazard, based
on the model there,

32
00:01:41,750 --> 00:01:46,510
predicted probability of having the event
by two months, based on the model was 20%.

33
00:01:46,510 --> 00:01:50,030
When their Martingale residual was
going to be zero because they're censored,

34
00:01:50,030 --> 00:01:50,980
they did not have the event,

35
00:01:50,980 --> 00:01:55,910
minus 0.2, minus their 20% probability of
having it by then.

36
00:01:55,910 --> 00:01:58,260
So we get a Martingale residual of -0.20.

37
00:01:58,260 --> 00:02:01,940
So people who are censored are going to
have negative values for

38
00:02:01,940 --> 00:02:03,430
the Martingale residual.

39
00:02:03,430 --> 00:02:08,480
Now for a subject to say have a event at
13 months, they have some predicted

40
00:02:08,480 --> 00:02:12,510
probability of having the event by 13
months based on their risk factors and

41
00:02:12,510 --> 00:02:13,180
based on the model.

42
00:02:13,180 --> 00:02:15,870
And let's say that comes out to be 50%,
their

43
00:02:15,870 --> 00:02:20,010
Martingale residual is going to be one
minus 50% because they did have the event.

44
00:02:20,010 --> 00:02:22,750
So they're going to have a positive
Martingale residual.

45
00:02:22,750 --> 00:02:26,410
Essentially, the Martingale residuals will
give you the excess failures.

46
00:02:26,410 --> 00:02:30,630
Plotting these can be useful especially
for evaluating whether or

47
00:02:30,630 --> 00:02:33,330
not a continuous predictor actually has

48
00:02:33,330 --> 00:02:37,680
a linear relationship with the outcome
variable here, the log hazard.

49
00:02:37,680 --> 00:02:40,360
And we're going to get into details on
that in a future module.

50
00:02:40,360 --> 00:02:43,370
But I'll just show you an example of a
Martingale residual plot,

51
00:02:43,370 --> 00:02:47,930
plotting the predictor depression score
against the Martingale residuals here.

52
00:02:47,930 --> 00:02:51,010
So we're going to do some of those plots
in a future module.

53
00:02:51,010 --> 00:02:54,320
Another type of residual that's directly
related to the Martingale residual is

54
00:02:54,320 --> 00:02:55,860
called the deviance residual.

55
00:02:55,860 --> 00:03:00,130
It's basically just take the Martingale
residuals and turn it, normalize it,

56
00:03:00,130 --> 00:03:03,420
make it into a normally distributed
variable.

57
00:03:03,420 --> 00:03:05,140
Makes it easier to interpret.

58
00:03:05,140 --> 00:03:08,030
These residuals are going to be
symmetrically distributed about zero.

59
00:03:08,030 --> 00:03:09,600
They're going to have z scores.

60
00:03:09,600 --> 00:03:12,590
So you know that if somebody has a z score
of positive four or

61
00:03:12,590 --> 00:03:16,200
negative four that that person doesn't
really fit the model very well.

62
00:03:16,200 --> 00:03:20,020
Observations with large deviance residuals
again are poorly predicted by the model.

63
00:03:20,020 --> 00:03:23,380
So, these behave more like the residuals
from ordinary regressions which we're

64
00:03:23,380 --> 00:03:24,638
kind of more use to.

65
00:03:24,638 --> 00:03:27,700
We're expecting them to be symmetrically
distributed around zero and

66
00:03:27,700 --> 00:03:29,830
have a standard deviation of one.

67
00:03:29,830 --> 00:03:32,350
Negative observations, it's going to be
negative.

68
00:03:32,350 --> 00:03:35,060
These deviance residuals will be below
zero for

69
00:03:35,060 --> 00:03:38,759
people who have longer than expected
observed survival times.

70
00:03:39,870 --> 00:03:42,940
And you can plot the deviance residuals
against the covariates to look for

71
00:03:42,940 --> 00:03:46,310
any unusual patterns, the same way we do
for a linear regression or to look for

72
00:03:46,310 --> 00:03:48,900
people who don't seem to fit the model
well.

73
00:03:48,900 --> 00:03:52,620
So again, I'm plotting the deviance
residuals against depression score,

74
00:03:52,620 --> 00:03:53,790
from a data set.

75
00:03:53,790 --> 00:03:56,310
It's pretty well, nicely, you know,

76
00:03:56,310 --> 00:04:00,340
kind of randomly distributed around zero,
as you would expect.

77
00:04:00,340 --> 00:04:04,160
There's a few people who have z scores
that are a little out of bounds, but

78
00:04:04,160 --> 00:04:06,010
it's a pretty big data set, so having one
or

79
00:04:06,010 --> 00:04:09,390
two people around a z score of three
actually would be expected, so

80
00:04:09,390 --> 00:04:12,830
I don't see anybody here who looks like a
huge outlier.

81
00:04:12,830 --> 00:04:14,450
So those are the deviance residuals.

82
00:04:15,470 --> 00:04:19,400
The Schoenfeld residuals turn out, in a
way, to be the most interesting.

83
00:04:19,400 --> 00:04:21,700
We're going to use the Schoenfeld
residuals for

84
00:04:21,700 --> 00:04:23,849
evaluating the proportional hazards
assumption.

85
00:04:24,880 --> 00:04:28,630
Schoenfeld residuals were proposed in
1982, and there's the reference.

86
00:04:28,630 --> 00:04:32,010
The key to understanding the Schoenfeld
residuals is that we're no longer going to

87
00:04:32,010 --> 00:04:33,840
have a single residual for

88
00:04:33,840 --> 00:04:38,100
each individual, which is what you're used
to from other regression models.

89
00:04:38,100 --> 00:04:41,110
What we're going to have instead is a
separate residual for

90
00:04:41,110 --> 00:04:44,060
each person for each covariate.

91
00:04:44,060 --> 00:04:47,000
So if I have age and weight in the model.

92
00:04:47,000 --> 00:04:49,340
Then I'm going to have residuals for age
and

93
00:04:49,340 --> 00:04:51,650
I'm going to have residuals for weight.

94
00:04:51,650 --> 00:04:55,960
But I'm only going to have residuals for
people who have the event.

95
00:04:55,960 --> 00:04:58,860
I will not have any residuals for people
who did not have the event.

96
00:05:00,870 --> 00:05:03,080
So let me explain now how they work.

97
00:05:03,080 --> 00:05:07,020
So the Schoenfeld residual is going to be
the covariant value for

98
00:05:07,020 --> 00:05:10,070
the individual that had the event, that
failed at a given time.

99
00:05:10,070 --> 00:05:14,018
So let's say a time is equal to two months
into the study.

100
00:05:14,018 --> 00:05:19,030
Subject 7 died.

101
00:05:19,030 --> 00:05:20,620
If the outcome here is death.

102
00:05:20,620 --> 00:05:26,220
And let's say that Subject 7 is 65 years
old.

103
00:05:26,220 --> 00:05:29,050
So for that, and let's say age is in our
model, okay.

104
00:05:29,050 --> 00:05:31,610
So we have a co-variant age in our model.

105
00:05:31,610 --> 00:05:35,460
Subject 7, the observed value is 65 at the
time they died,

106
00:05:35,460 --> 00:05:38,720
and we can come up with an expected value.

107
00:05:38,720 --> 00:05:41,370
What did we expect the age to be for

108
00:05:41,370 --> 00:05:43,380
the person who died two months into this
study?

109
00:05:43,380 --> 00:05:47,830
And we're going to subtract those and come
up with a residual specifically for age or

110
00:05:47,830 --> 00:05:48,570
for a particular covariate.

111
00:05:48,570 --> 00:05:53,580
So how do we come up with that expected
value for the covariate at time t?

112
00:05:53,580 --> 00:05:57,040
So again, this is at two months, what do
we expect in terms of,

113
00:05:57,040 --> 00:06:01,110
what do we, how old do we expect the
person who died at two months to be?

114
00:06:01,110 --> 00:06:05,470
We can calculate that as an expected value
is a weighted average of the covariant,

115
00:06:05,470 --> 00:06:08,550
weighted by the likelihood of failure for
each individual who is

116
00:06:08,550 --> 00:06:12,840
actually still at risk at two months, at
time t in the study.

117
00:06:12,840 --> 00:06:15,550
So the residual is the covariant value for

118
00:06:15,550 --> 00:06:19,690
the person who had the event and the
expected value for that covariant for

119
00:06:19,690 --> 00:06:23,000
say age, among everybody who's still at
risk at that time.

120
00:06:23,000 --> 00:06:25,350
And that's equal to everybody's values.

121
00:06:25,350 --> 00:06:28,350
So everybody who's at risk, their age,
weighted by a probability.

122
00:06:28,350 --> 00:06:31,870
And the probability is the probability
that they would have the event that they

123
00:06:31,870 --> 00:06:33,550
would have failed by time t.

124
00:06:34,700 --> 00:06:39,320
So for example, if a person was 56 years
old when they died,

125
00:06:39,320 --> 00:06:41,440
we can calculate the expected value for

126
00:06:41,440 --> 00:06:45,660
age and everybody, P is probability and
everybody who's at risk,

127
00:06:45,660 --> 00:06:49,830
we're going to multiply their age times
the probability that they would have died.

128
00:06:49,830 --> 00:06:50,810
They would've had the event.

129
00:06:51,840 --> 00:06:54,740
So, kind of conceptually, what we're
saying that the person who died was 56.

130
00:06:54,740 --> 00:06:57,550
And based on the fitted model, how likely
is

131
00:06:57,550 --> 00:07:03,090
it that the person who died would've been
56, rather than, say, older or younger?

132
00:07:03,090 --> 00:07:07,410
Were we expecting the person who dies now
to be 56, or something older or younger?

133
00:07:07,410 --> 00:07:08,550
That's the general idea.

134
00:07:08,550 --> 00:07:13,550
And this is probably best illustrated by
just giving some hypothetical example but

135
00:07:13,550 --> 00:07:14,600
with real numbers.

136
00:07:14,600 --> 00:07:17,020
So, let's say we had five people left in
our risk set,

137
00:07:17,020 --> 00:07:19,670
at event time, seven months into the
study.

138
00:07:19,670 --> 00:07:24,569
We had a 55 year old female smoker, a 45
year old male nonsmoker, a female 67

139
00:07:24,569 --> 00:07:29,220
year old smoker, a male 58 year old
smoker, a male 70 year old smoker.

140
00:07:29,220 --> 00:07:34,530
And what we have in our Cox regression
model, the predictors are gender, age and

141
00:07:34,530 --> 00:07:37,520
smoking status, non-smoker or smoker.

142
00:07:37,520 --> 00:07:41,310
But let's say that at seven months, it's
the 55 year old smoker,

143
00:07:41,310 --> 00:07:45,200
the female 55 year old smoker, who is the
one who actually had the event.

144
00:07:45,200 --> 00:07:49,370
So we're going to calculate the,
Schoenfeld residuals for her for,

145
00:07:49,370 --> 00:07:53,050
we can calculate them for age, for smoking
status, and for gender.

146
00:07:55,550 --> 00:08:00,020
So let's say based on our model, based on
everybody's age, smoking status, and

147
00:08:00,020 --> 00:08:04,210
gender, we can calculate The predicted
probability that they would have died,

148
00:08:04,210 --> 00:08:08,640
their cumulative hazard of dying by time
7, we can calculate that for

149
00:08:08,640 --> 00:08:10,340
each person, call it p-hat.

150
00:08:10,340 --> 00:08:13,114
So let's say we do that, based on the
model,

151
00:08:13,114 --> 00:08:17,432
the female 55 year old smoker had a 10%
chance of dying by time 7.

152
00:08:18,440 --> 00:08:20,330
The second person, it was 5%, and so on,
so

153
00:08:20,330 --> 00:08:22,220
just based on the fitted model, this is
what comes out.

154
00:08:22,220 --> 00:08:24,290
You can see that people who were smokers
and

155
00:08:24,290 --> 00:08:28,630
older have higher probabilities of having
died by seven months into the study.

156
00:08:28,630 --> 00:08:31,150
So what is the expected value for age,
then, for

157
00:08:31,150 --> 00:08:33,410
the person who failed at seven months?

158
00:08:33,410 --> 00:08:36,610
We just do an expected value in the normal
way, we take the age for

159
00:08:36,610 --> 00:08:40,410
everybody, weighted by their predicted
probability of dying.

160
00:08:40,410 --> 00:08:43,070
And coming out with, if we calculate it
out,

161
00:08:43,070 --> 00:08:46,780
that they predicted, the expected value
for age here is 60.

162
00:08:46,780 --> 00:08:50,410
So we were expecting somebody, who the
person to, who failed at 7 months,

163
00:08:50,410 --> 00:08:51,700
actually to be a little bit older.

164
00:08:51,700 --> 00:08:53,450
She was a little bit younger than
expected.

165
00:08:53,450 --> 00:08:58,800
So we do, 55, her, her age, the one who
died, her age, minus the expected value.

166
00:08:58,800 --> 00:09:00,650
So she was a little bit younger than I
expected.

167
00:09:00,650 --> 00:09:02,510
Her Schoenfeld residual is negative five.

168
00:09:03,940 --> 00:09:05,970
We can also do the same thing for gender.

169
00:09:05,970 --> 00:09:10,400
Gender's a binary variable, so, male is 0
here, female is 1.

170
00:09:10,400 --> 00:09:12,130
So, everybody who had,

171
00:09:12,130 --> 00:09:16,900
was a female gets a 0 value weighted by
their predicted probability of failure.

172
00:09:16,900 --> 00:09:19,620
Males get 1 weighted by their predicted
probabilities.

173
00:09:19,620 --> 00:09:22,610
When we add these all up we have a value
of 0.55.

174
00:09:22,610 --> 00:09:25,080
That means that we were slightly more
expecting,

175
00:09:25,080 --> 00:09:28,640
expecting a male a little bit more than we
were expecting a female to die here.

176
00:09:28,640 --> 00:09:33,400
So men, males have a slightly higher risk
of dying was the point of this study.

177
00:09:33,400 --> 00:09:37,830
So, she's a female, so her value for the
co-variate gender is zero.

178
00:09:37,830 --> 00:09:42,400
We subtract the expected value of .55, so
she's, gets a value for

179
00:09:42,400 --> 00:09:44,430
this Schoenfeld residual of negative .55.

180
00:09:44,430 --> 00:09:46,120
And so on.

181
00:09:46,120 --> 00:09:47,800
So we can calculate for

182
00:09:47,800 --> 00:09:51,220
every person who had an event, for every
covariant, Schoenfeld residual.

183
00:09:52,330 --> 00:09:56,020
So what's neat about he Schoenfeld
residuals is because they're calculated at

184
00:09:56,020 --> 00:10:00,500
every event time, we can actually plot the
Schoenfeld residuals against time.

185
00:10:00,500 --> 00:10:04,460
And that will tell us something about the
proportional hazards assumption.

186
00:10:04,460 --> 00:10:08,300
So in principle, the Schoenfeld residuals
should be independent of time.

187
00:10:08,300 --> 00:10:12,840
If you plot them and you see a pattern, a
nonrandom pattern, that's evidence of

188
00:10:12,840 --> 00:10:16,665
a violation, not the proportional hazards
assumption for that co-variate.

189
00:10:16,665 --> 00:10:20,390
So for example, going back, imagine we're
talking about age again.

190
00:10:20,390 --> 00:10:22,909
So here is the Schoenfeld residuals for
age.

191
00:10:24,880 --> 00:10:29,910
If I plot those against time, well, if the
hazard ratio for age is changing over

192
00:10:29,910 --> 00:10:35,680
time, it's getting bigger or smaller over
time, then what you might see is that

193
00:10:35,680 --> 00:10:39,650
when you plot this Schoenfeld residuals,
there's some distinct pattern across time.

194
00:10:39,650 --> 00:10:43,420
The Schoenfeld residuals are say, getting
bigger with time.

195
00:10:43,420 --> 00:10:49,330
[SOUND] More away from, you know, having
getting further away from 0 here,

196
00:10:49,330 --> 00:10:53,020
so if you plot it, it might look like, the
Schoenfeld residuals,

197
00:10:53,020 --> 00:10:57,970
if you plot a curve here are getting
higher with time or something like that.

198
00:10:57,970 --> 00:11:00,546
So, we can just plot the Schoenfeld
residuals for

199
00:11:00,546 --> 00:11:02,540
a particular covariate against time.

200
00:11:02,540 --> 00:11:04,874
We're going to talk more about this in a
upcoming module.

201
00:11:04,874 --> 00:11:08,350
But just to give you an example, here's an
example of Schoenfeld residuals for

202
00:11:08,350 --> 00:11:11,830
age from a particular data set plotted
over time.

203
00:11:11,830 --> 00:11:14,400
Looks like there's no real pattern with
time.

204
00:11:14,400 --> 00:11:17,460
So that would indicate that, that
proportional hazard assumption for

205
00:11:17,460 --> 00:11:18,790
age was met.

206
00:11:18,790 --> 00:11:22,460
But here is a plot this was a binary
predictor.

207
00:11:22,460 --> 00:11:25,470
You were either randomized to treatment or
to control.

208
00:11:25,470 --> 00:11:28,860
A plot of those Schoenfeld individuals for
that treatment variable across time and

209
00:11:28,860 --> 00:11:30,210
you can see a distinct pattern.

210
00:11:30,210 --> 00:11:32,000
It's a little hard to see with binary
variables but

211
00:11:32,000 --> 00:11:37,040
we get a smooth curve here, clearly this
the residuals are increasing with time.

212
00:11:37,040 --> 00:11:40,370
This one actually violates proportional
hazards.

213
00:11:40,370 --> 00:11:43,480
So, just common uses of the different
residuals that we get out.

214
00:11:43,480 --> 00:11:47,020
So the Martingale residuals, the most
common use of the Martingale residuals is

215
00:11:47,020 --> 00:11:50,990
you can plot the Martingale residuals
against your continuous predictors to

216
00:11:50,990 --> 00:11:54,270
check whether or not they're actually
linear in the log hazard and

217
00:11:54,270 --> 00:11:57,330
we do have an assumption of linearity
here.

218
00:11:57,330 --> 00:12:01,530
The deviance residuals are often used
because they're nice z scores.

219
00:12:01,530 --> 00:12:04,570
They can be used to check for outliers for
people who have very high or

220
00:12:04,570 --> 00:12:08,570
very low Z scores and the Shoenfeld
residuals as I've already alluded to

221
00:12:08,570 --> 00:12:11,770
you plot those against time to check the
proportional hazards assumption.
